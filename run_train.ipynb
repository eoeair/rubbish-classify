{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa8cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载类别权重: {0: 1.3681657848324515, 1: 1.3126057529610828, 2: 2.1300109829763865, 3: 1.4510849233071454, 4: 0.24280125195618155, 5: 2.055511393746688, 6: 1.6812960554833116, 7: 1.2313492063492064, 8: 1.4947013487475915, 9: 0.6539790929017029, 10: 1.8549736967957915, 11: 1.668279569892473}\n",
      "2025-06-30 21:48:52.986792: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-06-30 21:48:52.986834: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-06-30 21:48:52.986844: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "Step:500_Train Acc@1: 0.6875 loss: 0.8101\n",
      "2025-06-30 21:50:02.447635: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "Step:500_Val Acc@1: 0.6576 loss: 1.1468\n",
      "Step:1000_Train Acc@1: 0.6562 loss: 0.8111\n",
      "Step:1000_Val Acc@1: 0.7019 loss: 0.9888\n",
      "Step:1500_Train Acc@1: 0.7812 loss: 0.8326\n",
      "Step:1500_Val Acc@1: 0.7169 loss: 0.9292\n",
      "Step:2000_Train Acc@1: 0.7812 loss: 0.8478\n",
      "Step:2000_Val Acc@1: 0.7371 loss: 0.8224\n",
      "Step:2500_Train Acc@1: 0.7500 loss: 0.9652\n",
      "Step:2500_Val Acc@1: 0.7229 loss: 0.8462\n",
      "Step:3000_Train Acc@1: 0.7500 loss: 0.5099\n",
      "Step:3000_Val Acc@1: 0.7741 loss: 0.7629\n",
      "Step:3500_Train Acc@1: 0.8906 loss: 0.5590\n",
      "Step:3500_Val Acc@1: 0.7612 loss: 0.7487\n",
      "Step:4000_Train Acc@1: 0.8438 loss: 0.4885\n",
      "Step:4000_Val Acc@1: 0.7887 loss: 0.7304\n",
      "Step:4500_Train Acc@1: 0.8594 loss: 0.4210\n",
      "Step:4500_Val Acc@1: 0.7938 loss: 0.6795\n",
      "Step:5000_Train Acc@1: 0.8438 loss: 0.4113\n",
      "Step:5000_Val Acc@1: 0.7736 loss: 0.7199\n",
      "Step:5500_Train Acc@1: 0.8594 loss: 0.4697\n",
      "Step:5500_Val Acc@1: 0.7908 loss: 0.6586\n",
      "Step:6000_Train Acc@1: 0.8594 loss: 0.3165\n",
      "Step:6000_Val Acc@1: 0.7796 loss: 0.6870\n",
      "Step:6500_Train Acc@1: 0.9219 loss: 0.3117\n",
      "Step:6500_Val Acc@1: 0.8119 loss: 0.6259\n",
      "Step:7000_Train Acc@1: 0.9219 loss: 0.2793\n",
      "Step:7000_Val Acc@1: 0.8179 loss: 0.6302\n",
      "Step:7500_Train Acc@1: 0.9531 loss: 0.3093\n",
      "Step:7500_Val Acc@1: 0.8209 loss: 0.6361\n",
      "Step:8000_Train Acc@1: 0.8125 loss: 0.5724\n",
      "Step:8000_Val Acc@1: 0.8088 loss: 0.6378\n",
      "Step:8500_Train Acc@1: 0.9062 loss: 0.3896\n",
      "Step:8500_Val Acc@1: 0.8192 loss: 0.6727\n",
      "Step:9000_Train Acc@1: 0.9062 loss: 0.2534\n",
      "Step:9000_Val Acc@1: 0.8295 loss: 0.6335\n",
      "Step:9500_Train Acc@1: 0.9688 loss: 0.1695\n",
      "Step:9500_Val Acc@1: 0.8277 loss: 0.6392\n",
      "Step:10000_Train Acc@1: 0.8906 loss: 0.1863\n",
      "Step:10000_Val Acc@1: 0.8260 loss: 0.5975\n",
      "Step:10500_Train Acc@1: 0.9531 loss: 0.1357\n",
      "Step:10500_Val Acc@1: 0.8131 loss: 0.6543\n",
      "Step:11000_Train Acc@1: 0.8438 loss: 0.2851\n",
      "Step:11000_Val Acc@1: 0.8226 loss: 0.6787\n",
      "Step:11500_Train Acc@1: 0.8906 loss: 0.3914\n",
      "Step:11500_Val Acc@1: 0.8342 loss: 0.6263\n",
      "Step:12000_Train Acc@1: 0.9688 loss: 0.0996\n",
      "Step:12000_Val Acc@1: 0.8209 loss: 0.6148\n",
      "Step:12500_Train Acc@1: 0.9375 loss: 0.1690\n",
      "Step:12500_Val Acc@1: 0.8187 loss: 0.6412\n",
      "Step:13000_Train Acc@1: 0.9062 loss: 0.1696\n",
      "Step:13000_Val Acc@1: 0.8320 loss: 0.6797\n",
      "Step:13500_Train Acc@1: 0.9375 loss: 0.1037\n",
      "Step:13500_Val Acc@1: 0.8243 loss: 0.6405\n",
      "Step:14000_Train Acc@1: 0.9688 loss: 0.0850\n",
      "Step:14000_Val Acc@1: 0.8239 loss: 0.6447\n",
      "Step:14500_Train Acc@1: 0.7656 loss: 1.1028\n",
      "Step:14500_Val Acc@1: 0.7096 loss: 1.3333\n",
      "Step:15000_Train Acc@1: 0.9844 loss: 0.1323\n",
      "Step:15000_Val Acc@1: 0.8432 loss: 0.6670\n",
      "Step:15500_Train Acc@1: 0.9375 loss: 0.2699\n",
      "Step:15500_Val Acc@1: 0.8376 loss: 0.6316\n",
      "训练完成，最佳验证准确率: 0.8432\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
